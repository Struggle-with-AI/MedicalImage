{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Struggle-with-AI/MedicalImage/blob/main/GoogleNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Packages \\& Installation**"
      ],
      "metadata": {
        "id": "a8g2e7ANgcfQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9ZHGqIAbO6B",
        "outputId": "e9fd0ec7-6735-4477-f890-94d4f01ae58b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import copy\n",
        "import time"
      ],
      "metadata": {
        "id": "xyBNX5nfbXG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './'"
      ],
      "metadata": {
        "id": "ANML0vyKiQ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists('./data/working/mass_train.csv'))"
      ],
      "metadata": {
        "id": "OFl4p68zs91t",
        "outputId": "5ebb0691-37e4-4bdb-fb33-4ee45822e1ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataloader**"
      ],
      "metadata": {
        "id": "_tK0iIdvgn_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        # self.img_dir = img_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # image = Image.open(self.img_labels.iloc[idx, 1])\n",
        "        image = Image.open(self.img_dir + self.img_labels.iloc[idx, 11])\n",
        "        label = self.img_labels.iloc[idx, 14]\n",
        "\n",
        "        image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "FpGCMXN3bjtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_data = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Resize((224, 224)),\n",
        "                                     transforms.Normalize((0.5), (0.5))])"
      ],
      "metadata": {
        "id": "TiOlcwnDnSOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = MedicalDataset(path+'data/working/mass_train.csv', path, transform=transform_data)\n",
        "test_data = MedicalDataset(path+'data/working/mass_test.csv', path, transform=transform_data)"
      ],
      "metadata": {
        "id": "oL_QU3sOiEwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "id": "ZqRGCSFoiDIp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "2eda4667-1e98-4925-a3af-24b634c90b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0d79cff17076>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GoogleNet**"
      ],
      "metadata": {
        "id": "aNghcXVfsYmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Architecture**"
      ],
      "metadata": {
        "id": "rhHIHKdStRtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.bn(self.conv(x)))\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, im_channels, num_1x1, num_3x3_red, num_3x3, num_5x5_red, num_5x5, num_pool_proj):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "\n",
        "        self.one_by_one = ConvBlock(im_channels, num_1x1, kernel_size=1)\n",
        "\n",
        "        self.tree_by_three_red = ConvBlock(im_channels, num_3x3_red, kernel_size=1)\n",
        "        self.tree_by_three = ConvBlock(num_3x3_red, num_3x3, kernel_size=3, padding=1)\n",
        "\n",
        "        self.five_by_five_red = ConvBlock(im_channels, num_5x5_red, kernel_size=1)\n",
        "        self.five_by_five = ConvBlock(num_5x5_red, num_5x5, kernel_size=5, padding=2)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.pool_proj = ConvBlock(im_channels, num_pool_proj, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.one_by_one(x)\n",
        "\n",
        "        x2 = self.tree_by_three_red(x)\n",
        "        x2 = self.tree_by_three(x2)\n",
        "\n",
        "        x3 = self.five_by_five_red(x)\n",
        "        x3 = self.five_by_five(x3)\n",
        "\n",
        "        x4 = self.maxpool(x)\n",
        "        x4 = self.pool_proj(x4)\n",
        "\n",
        "        x = torch.cat([x1, x2, x3, x4], 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9bMEflGQsyoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=1, use_auxiliary=True, num_classes=1000):\n",
        "        super(Inception, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.conv2 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.linear = nn.Linear(1024, num_classes)\n",
        "\n",
        "        self.use_auxiliary = use_auxiliary\n",
        "        if use_auxiliary:\n",
        "            self.auxiliary4a = Auxiliary(512, num_classes)\n",
        "            self.auxiliary4d = Auxiliary(528, num_classes)\n",
        "\n",
        "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = None\n",
        "        z = None\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "        if self.training and self.use_auxiliary:\n",
        "            y = self.auxiliary4a(x)\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        if self.training and self.use_auxiliary:\n",
        "            z = self.auxiliary4d(x)\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x, y, z"
      ],
      "metadata": {
        "id": "4Tvz5nMjrYay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Auxiliary(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(Auxiliary, self).__init__()\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
        "        self.conv1x1 = ConvBlock(in_channels, 128, kernel_size=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        x = self.conv1x1(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zKcPH9ZYtExP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hi4a04KeG5xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run model**"
      ],
      "metadata": {
        "id": "ZvYaIFVztUTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Inception()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz4QP5lEtK7T",
        "outputId": "1ecfc55b-9a0d-42d2-d7ed-b15644bdcacd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception(\n",
              "  (conv1): ConvBlock(\n",
              "    (conv): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2): ConvBlock(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (linear): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "  (auxiliary4a): Auxiliary(\n",
              "    (avgpool): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
              "    (conv1x1): ConvBlock(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (fc2): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "    (dropout): Dropout(p=0.7, inplace=False)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (auxiliary4d): Auxiliary(\n",
              "    (avgpool): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
              "    (conv1x1): ConvBlock(\n",
              "      (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (fc2): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "    (dropout): Dropout(p=0.7, inplace=False)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (inception3a): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (inception3b): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (inception4a): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (inception4b): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (inception4c): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (inception4d): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (inception4e): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (inception5a): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (inception5b): InceptionBlock(\n",
              "    (one_by_one): ConvBlock(\n",
              "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three_red): ConvBlock(\n",
              "      (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (tree_by_three): ConvBlock(\n",
              "      (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five_red): ConvBlock(\n",
              "      (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (five_by_five): ConvBlock(\n",
              "      (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "    (pool_proj): ConvBlock(\n",
              "      (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define everything we need for training\n",
        "epochs = 1 #50\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7ilutbotP1Z",
        "outputId": "bb143648-58f9-48da-d6b9-8cabdb466a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=50, use_auxiliary=True):\n",
        "\n",
        "    since = time.time()\n",
        "    val_acc_history = []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]: # Iterate over data\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad() # Zero the parameter gradients\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n",
        "\n",
        "                    if phase == 'train': # Backward + optimize only if in training phase\n",
        "                        if use_auxiliary:\n",
        "                            outputs, aux1, aux2 = model(inputs)\n",
        "                            loss = criterion(outputs, labels) + 0.3 * criterion(aux1, labels) + 0.3 * criterion(aux2, labels)\n",
        "                        else:\n",
        "                            outputs, _, _ = model(inputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    if phase == 'val':\n",
        "                        outputs, _, _ = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "\n",
        "            if phase == 'val': # Adjust learning rate based on val loss\n",
        "                lr_scheduler.step(epoch_loss)\n",
        "\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "metadata": {
        "id": "ZAPRvyAetsvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, _ = train_model(model, {\"train\": train_dataloader, \"val\": test_dataloader}, criterion, optimizer, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Et0ql7QOt987",
        "outputId": "c26a33fe-b0b3-4bb4-c0d1-859764599d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d3f61aed7b83>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-d692120060dc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, use_auxiliary)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Iterate over data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-15e7fa15e3e5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# image = Image.open(self.img_labels.iloc[idx, 1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1Pbz8OHt-Kq",
        "outputId": "81ce1cf9-0394-4d2a-8d5f-19bca6261a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 16 15:26:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0             27W /   70W |     210MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}