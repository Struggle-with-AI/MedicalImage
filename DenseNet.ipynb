{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO95ocxeSXnQbaX8NhyVwOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Struggle-with-AI/MedicalImage/blob/main/DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5N8jcEU32wN",
        "outputId": "bd1e7603-6133-47fe-84ef-b88dcb3330b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import copy\n",
        "import time"
      ],
      "metadata": {
        "id": "S8TzQV7-35Td"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/MedicalImage/'\n"
      ],
      "metadata": {
        "id": "Pba3PA2ZfZyu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists('./MedicalImage/data/working/mass_train.csv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "786uJJRlfa7L",
        "outputId": "9063522c-78b0-4d2e-e7af-5b7a001cf2e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        # self.img_dir = img_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # image = Image.open(self.img_labels.iloc[idx, 1])\n",
        "        image = Image.open(self.img_dir + self.img_labels.iloc[idx, 11])\n",
        "        label = self.img_labels.iloc[idx, 14]\n",
        "\n",
        "        image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Pl_mbLHffeCF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_data = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Resize((224, 224)),\n",
        "                                     transforms.Normalize((0.5), (0.5))])"
      ],
      "metadata": {
        "id": "Wd0hqNJQfhcf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = MedicalDataset(path+'data/working/mass_train.csv', path, transform=transform_data)\n",
        "test_data = MedicalDataset(path+'data/working/mass_test.csv', path, transform=transform_data)"
      ],
      "metadata": {
        "id": "u9VGIVqDfl6y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "id": "JZGYR5jCfoeC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "import os\n",
        "\n",
        "class DenseLayer(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate, bottleneck=False, dropout_rate=0.0):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        inter_channels = 4 * growth_rate if bottleneck else in_channels\n",
        "        self.bottleneck = bottleneck\n",
        "\n",
        "        if bottleneck:\n",
        "            self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "            self.relu1 = nn.ReLU(inplace=True)\n",
        "            self.conv1 = nn.Conv2d(in_channels, inter_channels, kernel_size=1, bias=False)\n",
        "            in_channels = inter_channels\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout2d(p=dropout_rate) if dropout_rate > 0 else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        if self.bottleneck:\n",
        "            out = self.conv1(self.relu1(self.bn1(out)))\n",
        "        out = self.conv2(self.relu2(self.bn2(out)))\n",
        "        if self.dropout:\n",
        "            out = self.dropout(out)\n",
        "        return torch.cat([x, out], 1)\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_layers, in_channels, growth_rate, bottleneck=False, dropout_rate=0.0):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(num_layers):\n",
        "            layers.append(DenseLayer(in_channels + i * growth_rate, growth_rate, bottleneck, dropout_rate))\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, in_channels, compression=0.5):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        out_channels = int(in_channels * compression)\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(self.relu(self.bn(x)))\n",
        "        return self.pool(x)\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        self.growth_rate = config.get('growth_rate', 12)\n",
        "        self.num_blocks = config.get('num_blocks', 3)\n",
        "        self.layers_per_block = config.get('layers_per_block', 4)\n",
        "        self.init_channels = config.get('init_channels', 24)\n",
        "        self.compression = config.get('compression', 0.5)\n",
        "        self.dropout_rate = config.get('dropout_rate', 0.0)\n",
        "        self.bottleneck = config.get('bottleneck', False)\n",
        "        self.num_classes = config.get('num_classes', 10)\n",
        "        self.num_epochs = config.get('num_epochs', 50)\n",
        "        self.patience = config.get('patience', 5)\n",
        "\n",
        "        self.init_conv = nn.Conv2d(1, self.init_channels, kernel_size=3, padding=1, bias=False)\n",
        "        channels = self.init_channels\n",
        "        self.features = nn.Sequential()\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            block = DenseBlock(self.layers_per_block, channels, self.growth_rate,\n",
        "                               bottleneck=self.bottleneck, dropout_rate=self.dropout_rate)\n",
        "            self.features.add_module(f'dense_block_{i + 1}', block)\n",
        "            channels += self.layers_per_block * self.growth_rate\n",
        "            if i != self.num_blocks - 1:\n",
        "                trans = TransitionLayer(channels, compression=self.compression)\n",
        "                self.features.add_module(f'transition_{i + 1}', trans)\n",
        "                channels = int(channels * self.compression)\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(channels, self.num_classes)\n",
        "\n",
        "        self.train_accs, self.val_accs, self.losses = [], [], []\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.init_conv(x)\n",
        "        x = self.features(x)\n",
        "        x = self.relu(self.bn(x))\n",
        "        x = self.global_pool(x).view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "    def fit(self, train_loader, val_loader, optimizer, criterion, device,\n",
        "            num_epochs=50, patience=5, verbose=True):\n",
        "\n",
        "        since = time.time()\n",
        "        best_model = copy.deepcopy(self.state_dict())\n",
        "        best_acc = 0.0\n",
        "        no_improve = 0\n",
        "\n",
        "        self.train_accs, self.val_accs, self.losses = [], [], []\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            running_loss = 0.0\n",
        "            correct_train = 0\n",
        "            total_train = 0\n",
        "\n",
        "            for xb, yb in train_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(xb)\n",
        "                loss = criterion(outputs, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_train += yb.size(0)\n",
        "                correct_train += (predicted == yb).sum().item()\n",
        "\n",
        "            train_acc = correct_train / total_train\n",
        "            self.train_accs.append(train_acc)\n",
        "            self.losses.append(running_loss / len(train_loader))\n",
        "\n",
        "            val_acc = self.evaluate(val_loader, device)\n",
        "            self.val_accs.append(val_acc)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Epoch {epoch+1:02d} | Loss: {self.losses[-1]:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                best_model = copy.deepcopy(self.state_dict())\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= patience:\n",
        "                    print(f\"üîÅ Early stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print(f\"üèÅ Best Val Accuracy: {best_acc:.4f}\")\n",
        "\n",
        "    def evaluate(self, loader, device):\n",
        "        self.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                outputs = self(xb)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += yb.size(0)\n",
        "                correct += (predicted == yb).sum().item()\n",
        "        return correct / total\n",
        "\n",
        "    def visualize_training(self, save_path=\"training_plot.png\"):\n",
        "        epochs = range(1, len(self.train_accs) + 1)\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, self.losses, label='Train Loss')\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training Loss\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, self.train_accs, label='Train Acc')\n",
        "        plt.plot(epochs, self.val_accs, label='Val Acc')\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(\"Train vs Val Accuracy\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Training plot saved to {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def save_model(self, path=\"best_model.pth\"):\n",
        "        torch.save(self.state_dict(), path)\n",
        "        print(f\"Model saved to {path}\")\n",
        "\n",
        "    def load_model(self, path=\"best_model.pth\"):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "        print(f\"Model loaded from {path}\")"
      ],
      "metadata": {
        "id": "GI99VuUXf1mO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "config = {\n",
        "    'growth_rate': 12,\n",
        "    'num_blocks': 3,\n",
        "    'layers_per_block': 4,\n",
        "    'init_channels': 24,\n",
        "    'compression': 0.5,\n",
        "    'dropout_rate': 0.1,\n",
        "    'bottleneck': True,\n",
        "    'num_classes': 10,\n",
        "    'num_epochs': 1,\n",
        "    'patience': 5\n",
        "}\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "y1eU9ejTf4Yj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = DenseNet(config).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train\n",
        "model.fit(train_dataloader, test_dataloader, optimizer, criterion, device)\n",
        "\n",
        "# Save model + plot\n",
        "# model.save_model(\"best_densenet_cifar10.pth\")\n",
        "model.visualize_training(\"cifar10_training_plot.png\")\n",
        "\n",
        "# Final test\n",
        "test_acc = model.evaluate(test_dataloader, device)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "GGPGHWSKgAQG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "8e501821-8b54-48ba-dedf-bba4681bd751"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [24, 3, 3, 3], expected input[256, 1, 224, 224] to have 3 channels, but got 1 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3df12687f599>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Save model + plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-ddc78380cadb>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, val_loader, optimizer, criterion, device, num_epochs, patience, verbose)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-ddc78380cadb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [24, 3, 3, 3], expected input[256, 1, 224, 224] to have 3 channels, but got 1 channels instead"
          ]
        }
      ]
    }
  ]
}