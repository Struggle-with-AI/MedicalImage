{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load Pretrained CNN Model (Can replace Inception-V3 with ResNet, CLIP, etc.)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = models.inception_v3(pretrained=True).to(device)  # Change this for a different model\n",
    "model.eval()\n",
    "\n",
    "# Define Image Transform for Feature Extraction (Change size if using a different model)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Adjust size for different models (224x224 for ResNet, etc.)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Extract Features from an Image Segment\n",
    "def extract_features(image):\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Transform and add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image).cpu().numpy().flatten()  # Extract features (adjust for CLIP)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import rgb2lab\n",
    "from PIL import Image\n",
    "\n",
    "# Function to Perform Multi-Resolution Segmentation\n",
    "def segment_image(image_path, num_segments_list=[50, 100, 150]):  # Change number of segments\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for PIL compatibility\n",
    "    segments_list = []\n",
    "\n",
    "    for num_segments in num_segments_list:\n",
    "        segments = slic(image, n_segments=num_segments, compactness=10, sigma=1)  # Tune params\n",
    "        segments_list.append(segments)\n",
    "\n",
    "    return image, segments_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Function to Cluster Similar Image Segments\n",
    "def cluster_segments(image_path, num_clusters=10):  # Adjust number of clusters\n",
    "    image, segments_list = segment_image(image_path)\n",
    "    feature_vectors = []\n",
    "\n",
    "    for segments in segments_list:\n",
    "        unique_segments = np.unique(segments)\n",
    "        for seg_id in unique_segments:\n",
    "            mask = segments == seg_id\n",
    "            segment_img = np.zeros_like(image)\n",
    "            segment_img[mask] = image[mask]\n",
    "            pil_img = Image.fromarray(segment_img)\n",
    "            feature_vector = extract_features(pil_img)\n",
    "            feature_vectors.append(feature_vector)\n",
    "\n",
    "    # Perform Clustering on Extracted Features\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)  # Change clustering algorithm\n",
    "    cluster_labels = kmeans.fit_predict(feature_vectors)\n",
    "\n",
    "    return cluster_labels, feature_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Function to Extract Concepts from a Set of Images\n",
    "def extract_custom_concepts(image_folder):\n",
    "    all_clusters = []\n",
    "\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        if image_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            image_path = os.path.join(image_folder, image_file)\n",
    "            cluster_labels, _ = cluster_segments(image_path)\n",
    "            all_clusters.extend(cluster_labels)\n",
    "\n",
    "    # Count the Frequency of Each Cluster (Custom Concepts)\n",
    "    concept_counts = Counter(all_clusters)\n",
    "    \n",
    "    # Sort and Display the Most Common Concepts\n",
    "    sorted_concepts = sorted(concept_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Extracted Concepts (Clustered Patterns):\")\n",
    "    for concept, count in sorted_concepts:\n",
    "        print(f\"Concept {concept}: {count} occurrences\")\n",
    "\n",
    "    return sorted_concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic Concept Extraction on a Folder of Images\n",
    "image_folder = \"path_to_images\"\n",
    "concepts = extract_custom_concepts(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Function to Visualize Image Segments in Clusters\n",
    "def visualize_clusters(image_path, num_clusters=5, samples_per_cluster=4):\n",
    "    image, segments_list = segment_image(image_path)\n",
    "    cluster_labels, feature_vectors = cluster_segments(image_path, num_clusters=num_clusters)\n",
    "\n",
    "    fig, axes = plt.subplots(num_clusters, samples_per_cluster, figsize=(10, 2 * num_clusters))\n",
    "    \n",
    "    cluster_to_segments = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "    # Group segments by cluster\n",
    "    for seg_id, cluster in enumerate(cluster_labels):\n",
    "        cluster_to_segments[cluster].append(seg_id)\n",
    "\n",
    "    # Plot samples from each cluster\n",
    "    for cluster_idx, seg_ids in cluster_to_segments.items():\n",
    "        sampled_segments = random.sample(seg_ids, min(samples_per_cluster, len(seg_ids)))\n",
    "\n",
    "        for j, seg_id in enumerate(sampled_segments):\n",
    "            mask = np.zeros_like(image)\n",
    "            for segments in segments_list:\n",
    "                mask[segments == seg_id] = image[segments == seg_id]\n",
    "\n",
    "            axes[cluster_idx, j].imshow(mask)\n",
    "            axes[cluster_idx, j].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Visualization of {num_clusters} Concept Clusters\", fontsize=14)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
